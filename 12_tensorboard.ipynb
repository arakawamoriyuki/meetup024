{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorbaoad\n",
    "\n",
    "tensorbaoadをフル活用したmnist分類のサンプル。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-labels-idx1-ubyte.gz\n",
      "Starting run for lr_1E-03,conv=2,fc=2\n",
      "Starting run for lr_1E-03,conv=1,fc=2\n",
      "Starting run for lr_1E-03,conv=2,fc=1\n",
      "Starting run for lr_1E-03,conv=1,fc=1\n",
      "Starting run for lr_1E-04,conv=2,fc=2\n",
      "Starting run for lr_1E-04,conv=1,fc=2\n",
      "Starting run for lr_1E-04,conv=2,fc=1\n",
      "Starting run for lr_1E-04,conv=1,fc=1\n",
      "Starting run for lr_1E-05,conv=2,fc=2\n",
      "Starting run for lr_1E-05,conv=1,fc=2\n",
      "Starting run for lr_1E-05,conv=2,fc=1\n",
      "Starting run for lr_1E-05,conv=1,fc=1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import urllib\n",
    "\n",
    "if sys.version_info[0] >= 3:\n",
    "  from urllib.request import urlretrieve\n",
    "else:\n",
    "  from urllib import urlretrieve\n",
    "\n",
    "LOGDIR = '/tmp/mnist_tutorial/'\n",
    "GITHUB_URL ='https://raw.githubusercontent.com/mamcgrath/TensorBoard-TF-Dev-Summit-Tutorial/master/'\n",
    "\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=LOGDIR + 'data', one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "urlretrieve(GITHUB_URL + 'labels_1024.tsv', LOGDIR + 'labels_1024.tsv')\n",
    "urlretrieve(GITHUB_URL + 'sprite_1024.png', LOGDIR + 'sprite_1024.png')\n",
    "\n",
    "# Add convolution layer\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    act = tf.nn.relu(conv + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "# Add fully connected layer\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return act\n",
    "\n",
    "\n",
    "def mnist_model(learning_rate, use_two_conv, use_two_fc, hparam):\n",
    "  tf.reset_default_graph()\n",
    "  sess = tf.Session()\n",
    "\n",
    "  # Setup placeholders, and reshape the data\n",
    "  x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "  x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "  tf.summary.image('input', x_image, 3)\n",
    "  y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "  if use_two_conv:\n",
    "    conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "    conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "  else:\n",
    "    conv1 = conv_layer(x_image, 1, 64, \"conv\")\n",
    "    conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "  flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64])\n",
    "\n",
    "\n",
    "  if use_two_fc:\n",
    "    fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "    embedding_input = fc1\n",
    "    embedding_size = 1024\n",
    "    logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "  else:\n",
    "    embedding_input = flattened\n",
    "    embedding_size = 7*7*64\n",
    "    logits = fc_layer(flattened, 7*7*64, 10, \"fc\")\n",
    "\n",
    "  with tf.name_scope(\"xent\"):\n",
    "    xent = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=y), name=\"xent\")\n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "  with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "  with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "  summ = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "  embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "  assignment = embedding.assign(embedding_input)\n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "  writer.add_graph(sess.graph)\n",
    "\n",
    "  config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "  embedding_config = config.embeddings.add()\n",
    "  embedding_config.tensor_name = embedding.name\n",
    "  embedding_config.sprite.image_path = LOGDIR + 'sprite_1024.png'\n",
    "  embedding_config.metadata_path = LOGDIR + 'labels_1024.tsv'\n",
    "  # Specify the width and height of a single thumbnail.\n",
    "  embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "  tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "\n",
    "  for i in range(501):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i % 5 == 0:\n",
    "      [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], y: batch[1]})\n",
    "      writer.add_summary(s, i)\n",
    "    if i % 100 == 0:\n",
    "      sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "      saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "  conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "  fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "  return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "\n",
    "def main():\n",
    "  # You can try adding some more learning rates\n",
    "  for learning_rate in [1E-3, 1E-4, 1E-5]:\n",
    "\n",
    "    # Include \"False\" as a value to try different model architectures\n",
    "    for use_two_fc in [True, False]:\n",
    "      for use_two_conv in [True, False]:\n",
    "        # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2)\n",
    "        hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "        print('Starting run for %s' % hparam)\n",
    "\n",
    "\t    # Actually run with the new settings\n",
    "        mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## なにをしてる？\n",
    "\n",
    "1. mnistサンプルデータをダウンロード\n",
    "2. 畳み込みニューラルネットワークで手書き文字を分類(複数のハイパーパラメータ、計12パターンで検証)\n",
    "  - 学習率0.001と0.01と0.1を使用した3つのパターン\n",
    "  - 1つの畳み込み層、2つの畳み込み層を使用した2つのパターン\n",
    "  - 1つのプーリング層、2つのプーリング層を使用した2つのパターン\n",
    "  \n",
    "## tensorboard起動\n",
    "\n",
    "上記の実行は結構時間かかります。でもtensorboardはリアルタイムに更新されるので途中でも観れる！\n",
    "とりあえず実行します。\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir /tmp/mnist_tutorial \n",
    "```\n",
    "\n",
    "## scalars\n",
    "\n",
    "accuracy(精度)とxent(クロスエントロピー)かあります。\n",
    "\n",
    "### 精度\n",
    "\n",
    "```\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "```\n",
    "\n",
    "精度は文字通り、精度の上昇具合を見る事ができ、どのハイパーパラメータを適用した学習が一番効率がいいかを調べる事ができます。\n",
    "ただし、かなり上昇している学習でも実行がすすむに連れて上昇しずらくなったり、逆に、最初はかなり上昇が遅いのに後半は他の学習より良い結果になったりします。\n",
    "\n",
    "### クロスエントロピー\n",
    "\n",
    "```\n",
    "tf.summary.scalar(\"xent\", xent)\n",
    "```\n",
    "\n",
    "クロスエントロピーは学習結果がどの程度間違っているかを示します。\n",
    "下がりきると、現在のデータからはもう学ぶべきものは少なくなった事を示します。\n",
    "\n",
    "## images\n",
    "\n",
    "```\n",
    "tf.summary.image('input', x_image, 3)\n",
    "```\n",
    "\n",
    "現在学習している実際の画像データを見る事ができます。\n",
    "\n",
    "## audio\n",
    "\n",
    "この例ではないですが、学習している実際の音声データもみる(聞く)ことができます。\n",
    "\n",
    "## graphs\n",
    "\n",
    "```\n",
    "with tf.name_scope(\"xent\"):\n",
    "```\n",
    "\n",
    "計算グラフを構築するとこのgraphsタブで計算過程を可視化できます。\n",
    "withを使う事で計算を名前をつけてひとまとまりにできます。\n",
    "\n",
    "学習している画像のサイズと枚数なども確認できるのでたたみ込みの理解が深まります。\n",
    "\n",
    "## distributions\n",
    "\n",
    "distributionsは各パラメータの分布を見る事ができます。\n",
    "バイアスや重みの変化度合いを確認できます。\n",
    "\n",
    "## histograms\n",
    "\n",
    "histogramsは上のdistributionsを度数分布にしたものです。 \n",
    "変化の度合いを確認できます。\n",
    "\n",
    "## embedding\n",
    "\n",
    "分類した画像をクラスタリングします。観てるだけで楽しい。\n",
    "まちがった分類をした画像がなぜその分類になったかを、パラメータ距離の近い画像を確認する事で原因を追求できます。\n",
    "例えば、1に近い7とか、0に近い6などです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
